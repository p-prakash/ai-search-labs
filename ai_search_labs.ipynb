{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv\n",
    "! pip install numpy\n",
    "! pip install azure-core\n",
    "! pip install azure-search-documents\n",
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient, SearchIndexingBufferedSender \n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    VectorSearch,  \n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,  \n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchProfile,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    VectorSearchAlgorithmMetric,\n",
    ")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the credentials for Azure AI Search from the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.environ.get('AI_SEARCH_KEY')\n",
    "endpoint = os.environ.get('AI_SEARCH_ENDPOINT')\n",
    "index_name = os.environ.get('AI_SEARCH_INDEX_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a search index in Azure AI Search with Vector Search enabled\n",
    "\n",
    "> _Note: If you want to change the fields in AI Search Index you should update it the below cell_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SearchIndexClient\n",
    "if key is None:\n",
    "    credential = DefaultAzureCredential()\n",
    "else:\n",
    "    credential = AzureKeyCredential(key)\n",
    "index_client: SearchIndexClient = SearchIndexClient(\n",
    "    endpoint=endpoint, credential=credential)\n",
    "\n",
    "# Check if the index exists, if not create it\n",
    "try:\n",
    "    index_client.get_index(name=index_name)\n",
    "    print(f'Index {index_name} already exists')\n",
    "except ResourceNotFoundError as ex:\n",
    "    # AI Search fields configuration\n",
    "    fields = [\n",
    "        SimpleField(name='id', type=SearchFieldDataType.String,\n",
    "                    key=True, filterable=True),\n",
    "        SearchableField(name='title', type=SearchFieldDataType.String),\n",
    "        SearchField(name='title_vector', type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                    searchable=True, vector_search_dimensions=1536, vector_search_profile_name='defaultHnswProfile'),\n",
    "        SearchableField(name='content', type=SearchFieldDataType.String),\n",
    "        SearchField(name='content_vector', type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                    searchable=True, vector_search_dimensions=1536, vector_search_profile_name='defaultHnswProfile'),\n",
    "        SearchableField(name='tag', type=SearchFieldDataType.String, filterable=True),\n",
    "        SearchableField(name='metadata', type=SearchFieldDataType.String)\n",
    "    ]\n",
    "    # Vector search configuration\n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name='defaultHnsw',\n",
    "                kind=VectorSearchAlgorithmKind.HNSW,\n",
    "                parameters=HnswParameters(\n",
    "                    m=4,\n",
    "                    ef_construction=400,\n",
    "                    ef_search=500,\n",
    "                    metric=VectorSearchAlgorithmMetric.COSINE\n",
    "                )\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"defaultHnswProfile\",\n",
    "                algorithm_configuration_name=\"defaultHnsw\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Create the search index with the vector search\n",
    "    index = SearchIndex(name=index_name, fields=fields,\n",
    "                        vector_search=vector_search)\n",
    "    index_client.create_index(index)\n",
    "    print(f'Successfully created index {index_name} with vector search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to generate embeddings for the provided text and perform cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text, client, model): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the credentials for Azure OpenAI Service from the environment variables and initialize the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment variables for the Azure OpenAI service\n",
    "aoai_endpoint = os.environ.get('AOAI_ENDPOINT')\n",
    "aoai_key = os.environ.get('AOAI_KEY')\n",
    "aoai_deployment = os.environ.get('AOAI_EMBEDDINGS_DEPLOYMENT')\n",
    "aoai_api_version = os.environ.get('AOAI_API_VERSION')\n",
    "\n",
    "# Initialize the AzureOpenAI client\n",
    "aoai_client = AzureOpenAI(api_key=aoai_key, api_version=aoai_api_version, azure_endpoint=aoai_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the product data from your API or load it from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = '/path_to_the_file/file.json'\n",
    "\n",
    "# Read the JSON file (make sure your data is list of dictionaries)\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    products_data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Search Client for Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(endpoint=endpoint, index_name=index_name, credential=AzureKeyCredential(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate embeddings of the title and content of the product data using the Azure OpenAI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_FILE = 'products_vector.json'\n",
    "\n",
    "with open(VECTOR_FILE, 'w', encoding='utf-8') as f:\n",
    "    f.write('[\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, product_data in enumerate(products_data):\n",
    "    print(f'Processing {i+1} of {len(products_data)}')\n",
    "    title_vector = generate_embeddings(product_data['title'], aoai_client, model=aoai_deployment)\n",
    "    content_vector = generate_embeddings(product_data['content'], aoai_client, model=aoai_deployment)\n",
    "    product_data['title_vector'] = title_vector\n",
    "    product_data['content_vector'] = content_vector\n",
    "\n",
    "    with open(VECTOR_FILE, 'a', encoding='utf-8') as f:\n",
    "        json.dump(product_data, f, ensure_ascii=False)\n",
    "        if i != len(products_data) - 1:\n",
    "                f.write(',\\n')\n",
    "\n",
    "with open(VECTOR_FILE, 'a', encoding='utf-8') as f:\n",
    "    f.write('\\n]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through your content such that you map your content based on the search index schema and upload the documents.\n",
    "\n",
    "_Note: Maximum of 1000 documents shall be uploaded per `upload_documents` API call_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_UPLOAD_BATCH_SIZE = 999\n",
    "\n",
    "with open(VECTOR_FILE, 'r', encoding='utf-8') as file:\n",
    "    vectorized_data = json.load(file)\n",
    "\n",
    "# Split vectorized_data into batches\n",
    "batches = [vectorized_data[i:i+MAX_UPLOAD_BATCH_SIZE] for i in range(0, len(vectorized_data), MAX_UPLOAD_BATCH_SIZE)]\n",
    "\n",
    "# Upload documents in batches\n",
    "for i, batch in enumerate(batches):\n",
    "    response = search_client.upload_documents(documents=batch)\n",
    "    # Check if all documents were successfully uploaded\n",
    "    if not all([r.succeeded for r in response]):\n",
    "        raise Exception(response)\n",
    "    \n",
    "    print(f'Batch {i+1} with {len(vectorized_data)} documents uploaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a hybrid search (keyword + vector) and get top 5 search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Product'\n",
    "\n",
    "\n",
    "query_embedding = generate_embeddings(query, aoai_client, model=aoai_deployment)\n",
    "vector_query = VectorizedQuery(vector=query_embedding, k_nearest_neighbors=5, fields=\"title_vector, content_vector\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[ vector_query ],\n",
    "    top=5\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Id: {result['id']}\")\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Content: {result['content']}\\n\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
